# 3.3.1. Handle Missing Values (if any)
# In this dataset, there are no missing values.  If there were, you'd use one of these methods:
# df.dropna(inplace=True)  # Remove rows with missing values
# df.fillna(df.mean(), inplace=True) # Fill missing values with the mean of the column

# 3.3.2. Feature Scaling (Scaling 'Amount' and 'Time' is important)
scaler = StandardScaler()
df['Amount'] = scaler.fit_transform(df[['Amount']]) #Scale the Amount column
df['Time'] = scaler.fit_transform(df[['Time']]) #Scale the Time column

# 3.3.3. Data Splitting (Training and Testing sets)
X = df.drop('Class', axis=1) # Features (independent variables) - all columns except 'Class'
y = df['Class']             # Target variable (dependent variable) - 'Class'

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
# test_size=0.2 means 20% of the data will be used for testing.
# random_state=42 ensures the split is reproducible.
# stratify=y  preserves the class distribution in both training and testing sets.

# 3.3.4.  Handling Class Imbalance (Very Important!) - using SMOTE
#  Since fraud is rare, we'll likely have a class imbalance (much more non-fraud than fraud).
#  We use SMOTE (Synthetic Minority Oversampling Technique) to balance the classes.
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Display the new class counts after SMOTE
print("Class distribution after SMOTE:")
print(pd.Series(y_train_smote).value_counts())

Explanation:
Missing Values: The code shows how to handle missing values if they exist (using dropna() or fillna()). The Credit Card Fraud dataset doesn't have missing values, but it is important to know how to deal with them.
Feature Scaling: It's very important to scale the 'Amount' and 'Time' features using StandardScaler. This is because these features have different scales compared to the V1-V28 features, and scaling helps the machine learning models work better. Scaling puts all the features on a similar scale (typically with a mean of 0 and a standard deviation of 1).
Data Splitting: The data is split into training and testing sets using train_test_split(). This is essential for evaluating the performance of the model on unseen data. stratify=y ensures that the class distribution is preserved in both sets.
Handling Class Imbalance: This is a critical step! Fraudulent transactions are typically rare. We use SMOTE (Synthetic Minority Oversampling Technique) to oversample the minority class (fraud) by creating synthetic samples. This helps the model learn to identify fraud more effectively.
